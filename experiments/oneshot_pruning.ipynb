{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pruner import * \n",
    "from models import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE=512\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./mnist-data', train=True,\n",
    "                                     download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./mnist-data', train=False,\n",
    "                                     download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=TEST_BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.96435546875, 0.03764837586786598)\n",
      "431078.0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "net = LeNet(trainloader, testloader)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load('./checkpoints/iterative-pruning/lt-mnist-1-trained'))\n",
    "print(net.test())\n",
    "print(net.param_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "_pruner = pickle.load(open('./experiment_data/iterative-pruning/lt-mnist-1.p', 'rb'))\n",
    "_pruner.masks.keys()\n",
    "\n",
    "pruner = SparsityPruner(net)\n",
    "pruner.masks = _pruner.masks\n",
    "\n",
    "pruner.apply_mask(mask_classifier=True)\n",
    "print(net.test())\n",
    "print(net.param_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "86676.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "conv1.bias\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "classifier.0.weight\n",
      "classifier.0.bias\n",
      "classifier.2.weight\n",
      "classifier.2.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = SparsityPruner(net)\n",
    "pruner.prune(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1125, 2.301564133167267)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "net = LeNet(trainloader, testloader)\n",
    "net = net.to(device)\n",
    "# torch.save(net.state_dict(), './checkpoints/lenet-lt-init-02')\n",
    "# net.load_state_dict(torch.load('./checkpoints/lenet-lt-03-3-trained'))\n",
    "net.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 15\n",
    "optimizer = optim.Adam(net.parameters(), lr=12e-4, weight_decay=5e-4)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    print('Starting epoch {}'.format(epoch+1))\n",
    "    plt_data = (train_losses, val_losses, train_accs, val_accs)\n",
    "    train_losses, val_losses, train_accs, val_accs = net.train_epoch(epoch, optimizer, plot='loss', data=plt_data, LOG=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), './checkpoints/lenet-lt-trained-02')\n",
    "# net.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet(trainloader, testloader)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load('./checkpoints/lenet-lt-trained-02'))\n",
    "val_acc, _ = net.test()\n",
    "print('Before pruning: {}, params: {}'.format(val_acc, net.param_count()))\n",
    "pruner = SparsityPruner(net)\n",
    "pruner.prune(0.2)\n",
    "print('After pruning: {}, params: {}'.format(net.test()[0], net.param_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "plt_data = (train_losses, val_losses, train_accs, val_accs)\n",
    "print('After pruning: {}'.format(net.test()))\n",
    "for epoch in range(1):\n",
    "    train_losses, val_losses, train_accs, val_accs = \\\n",
    "        net.train_epoch(epoch, optimizer, plot='acc', data=plt_data, LOG=25, pruner=pruner, early_stop=val_acc)\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    plt_data = (train_losses, val_losses, train_accs, val_accs)\n",
    "    pruner.apply_mask()\n",
    "    print('After retraining: accuracy: {}, params: {}'.format(net.test(), net.param_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), './checkpoints/lenet-lt-finetuned-02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain from winning ticket initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net_retrain = LeNet(trainloader, testloader)\n",
    "net_retrain = net.to(device)\n",
    "net_retrain.load_state_dict(torch.load('./checkpoints/lenet-lt-init-02'))\n",
    "net_retrain.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_masks = pruner.masks\n",
    "pruner_retrain = SparsityPruner(net_retrain)\n",
    "pruner_retrain.masks = _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 5\n",
    "optimizer = optim.SGD(net_retrain.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "pruner_retrain.apply_mask()\n",
    "print(net_retrain.param_count())\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    print('Starting epoch {}'.format(epoch+1))\n",
    "    plt_data = (train_losses, val_losses, train_accs, val_accs)\n",
    "    train_losses, val_losses, train_accs, val_accs = net.train_epoch(epoch, optimizer, plot='acc', data=plt_data, pruner=pruner_retrain, early_stop=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_retrain.test()[0] >= (val_acc- 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain from random reinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = LeNet(trainloader, testloader)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load('./checkpoints/lenet-lt-03-init'))\n",
    "net.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_masks = pruner.masks\n",
    "pruner_reinit = SparsityPruner(net)\n",
    "pruner_reinit.masks = _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 5\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "# pruner_reinit.apply_mask()\n",
    "# print(net.param_count())\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    print('Starting epoch {}'.format(epoch+1))\n",
    "    plt_data = (train_losses, val_losses, train_accs, val_accs)\n",
    "    train_losses, val_losses, train_accs, val_accs = net.train_epoch(epoch, optimizer, plot='acc', data=plt_data, pruner=pruner_reinit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW=1870\n",
    "\n",
    "orig_val = np.array(pd.read_csv('experiment_data/lt-mnist-init.csv')['val_accs'])\n",
    "orig_val = orig_val[:WINDOW]\n",
    "orig_train = np.array(pd.read_csv('experiment_data/lt-mnist-init.csv')['train_accs'])\n",
    "orig_train = orig_train[:WINDOW]\n",
    "\n",
    "rand_val = np.array(pd.read_csv('experiment_data/lt-mnist-rand-init.csv')['val_accs'])\n",
    "rand_train = np.array(pd.read_csv('experiment_data/lt-mnist-rand-init.csv')['train_accs'])\n",
    "rand_val = rand_val[:WINDOW]\n",
    "rand_train = rand_train[:WINDOW]\n",
    "\n",
    "reinit_train = list(pd.read_csv('experiment_data/lt-mnist-reinit.csv')['train_accs'])\n",
    "reinit_train = [0.0958984375] + reinit_train\n",
    "reinit_train = np.array(reinit_train)\n",
    "reinit_train = (reinit_train,np.repeat(reinit_train[-1], len(orig) - len(reinit_train)))\n",
    "reinit_train = np.concatenate(reinit_train)\n",
    "reinit_train = reinit_train[:WINDOW]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = pd.DataFrame({'base (0.2)': orig_val, \n",
    "              'retrain (0.2)': reinit_val,\n",
    "              'random (0.2)': rand_val}).plot(figsize=(3,3), legend=None)\n",
    "# fig = ax.get_figure()\n",
    "# fig.savefig('figures/mnist-lenet-lt-0.2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 1870\n",
    "\n",
    "orig_val = pd.read_csv('lt-mnist-init-0.1.csv')['val_accs']\n",
    "orig_val_01 = orig_val[:WINDOW]\n",
    "orig_train = np.array(pd.read_csv('lt-mnist-init-0.1.csv')['train_accs'])\n",
    "orig_train = orig_train[:WINDOW]\n",
    "\n",
    "rand_val = pd.read_csv('lt-mnist-rand-init-0.1.csv')['val_accs']\n",
    "rand_train = pd.read_csv('lt-mnist-rand-init-0.1.csv')['train_accs']\n",
    "rand_val_01 = rand_val[:WINDOW]\n",
    "rand_train = rand_train[:WINDOW]\n",
    "\n",
    "reinit_train = list(pd.read_csv('lt-mnist-reinit-0.1.csv')['train_accs'])\n",
    "reinit_train = [orig_train[-1]] + reinit_train\n",
    "reinit_train = np.array(reinit_train)\n",
    "reinit_train = (reinit_train,np.repeat(reinit_train[-1], len(orig) - len(reinit_train)))\n",
    "reinit_train = np.concatenate(reinit_train)\n",
    "reinit_train = reinit_train[:WINDOW]\n",
    "\n",
    "reinit_val = np.array(pd.read_csv('lt-mnist-reinit-0.1.csv')['val_accs'])\n",
    "reinit_vals = (reinit_val,np.repeat(reinit_val[-1], len(orig_val) - len(reinit_val)))\n",
    "reinit_val = np.concatenate(reinit_vals)\n",
    "reinit_val_01 = reinit_val[:WINDOW]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = pd.DataFrame({'base (0.1)': orig_val_01, \n",
    "              'retrain (0.1)': reinit_val_01,\n",
    "              'random (0.1)': rand_val_01}).plot(figsize=(3,3), legend=None)\n",
    "# fig = ax.get_figure()\n",
    "# fig.savefig('figures/mnist-lenet-lt-0.1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 600\n",
    "\n",
    "orig_val = np.array(pd.read_csv('lt-mnist-init-0.15.csv')['val_accs'])\n",
    "orig_val_15 = orig_val[:WINDOW]\n",
    "orig_train = np.array(pd.read_csv('lt-mnist-init-0.15.csv')['train_accs'])\n",
    "orig_train = orig_train[:WINDOW]\n",
    "\n",
    "rand_val = np.array(pd.read_csv('lt-mnist-rand-init-0.15.csv')['val_accs'])\n",
    "rand_train = np.array(pd.read_csv('lt-mnist-rand-init-0.15.csv')['train_accs'])\n",
    "rand_val_15 = rand_val[:WINDOW]\n",
    "rand_train = rand_train[:WINDOW]\n",
    "\n",
    "reinit_train = list(pd.read_csv('lt-mnist-reinit-0.15.csv')['train_accs'])\n",
    "reinit_train = [orig_train[-1]] + reinit_train\n",
    "reinit_train = np.array(reinit_train)\n",
    "reinit_train = (reinit_train,np.repeat(reinit_train[-1], len(orig) - len(reinit_train)))\n",
    "reinit_train = np.concatenate(reinit_train)\n",
    "reinit_train = reinit_train[:WINDOW]\n",
    "\n",
    "reinit_val = np.array(pd.read_csv('lt-mnist-reinit-0.15.csv')['val_accs'])\n",
    "reinit_vals = (reinit_val,np.repeat(reinit_val[-1], len(orig_val) - len(reinit_val)))\n",
    "reinit_val = np.concatenate(reinit_vals)\n",
    "reinit_val_15 = reinit_val[:WINDOW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3 = pd.DataFrame({'base (0.15)': orig_val_15, \n",
    "              'retrain (0.15)': reinit_val_15,\n",
    "              'random (0.15)': rand_val_15}).plot(figsize=(3,3), legend=None)\n",
    "# fig = ax.get_figure()\n",
    "# fig.savefig('figures/mnist-lenet-lt-0.15.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "# df1.plot(ax=axes[0,0])\n",
    "# df2.plot(ax=axes[0,1])\n",
    "\n",
    "a1 = pd.DataFrame({'base (0.15)': orig_val, \n",
    "              'reinit (org.)': reinit_val,\n",
    "              'reinit (rand.)': rand_val}).plot(figsize=(3,3), legend=None, ax=axes[0])\n",
    "a1.set(xlabel='p=0.8')\n",
    "\n",
    "a2 = pd.DataFrame({'base': orig_val_15, \n",
    "              'reinit (org.)': reinit_val_15,\n",
    "              'reinit (rand.)': rand_val_15}).plot(figsize=(3,3), legend=None, ax=axes[1])\n",
    "a2.set(xlabel='p=0.85')\n",
    "\n",
    "a3 = pd.DataFrame({'base': orig_val_01, \n",
    "              'reinit (org.)': reinit_val_01,\n",
    "              'reinit (rand.)': rand_val_01}).plot(figsize=(3,3), ax=axes[2], )\n",
    "a3.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "a3.set(xlabel='p=0.9')\n",
    "fig.set_size_inches(12,3)\n",
    "\n",
    "fig.savefig('figures/mnist-base-lt-small.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = len(orig_val)\n",
    "\n",
    "# lt-resnet18-cifar-init-.csv  lt-resnet18-cifar-rand-init.csv  lt-resnet18-cifar-reinit.csv\n",
    "\n",
    "orig_val = np.array(pd.read_csv('lt-resnet18-cifar-100e-init.csv')['val_accs'])\n",
    "# orig_val = orig_val[:WINDOW]\n",
    "orig_train = np.array(pd.read_csv('lt-resnet18-cifar-100e-init.csv')['train_accs'])\n",
    "# orig_train = orig_train[:WINDOW]\n",
    "\n",
    "rand_val = np.array(pd.read_csv('lt-resnet18-cifar-100e-rand-init.csv')['val_accs'])\n",
    "rand_train = np.array(pd.read_csv('lt-resnet18-cifar-100e-rand-init.csv')['train_accs'])\n",
    "reinit_vals = (rand_val,np.repeat(rand_val[-1], len(orig_val) - len(rand_val)))\n",
    "rand_val = rand_val[:WINDOW]\n",
    "rand_train = rand_train[:WINDOW]\n",
    "\n",
    "reinit_train = list(pd.read_csv('lt-resnet18-cifar-100e-reinit.csv')['train_accs'])\n",
    "reinit_train = [orig_train[-1]] + reinit_train\n",
    "reinit_train = np.array(reinit_train)\n",
    "reinit_train = (reinit_train,np.repeat(reinit_train[-1], len(orig_train) - len(reinit_train)))\n",
    "reinit_train = np.concatenate(reinit_train)\n",
    "# reinit_train = reinit_train[:WINDOW]\n",
    "\n",
    "reinit_val = np.array(pd.read_csv('lt-resnet18-cifar-100e-reinit.csv')['val_accs'])\n",
    "reinit_vals = (reinit_val,np.repeat(reinit_val[-1], len(orig_val) - len(reinit_val)))\n",
    "reinit_val = np.concatenate(reinit_vals)\n",
    "# reinit_val = reinit_val[:WINDOW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rand_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'base': orig_val, \n",
    "              'reinit (org)': reinit_val,\n",
    "              'reinig (rand)': rand_val}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE=512\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar-data', train=True,\n",
    "                                     download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar-data', train=False,\n",
    "                                     download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=TEST_BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, (x, label) = next(enumerate(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.333333333333334"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25000/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
